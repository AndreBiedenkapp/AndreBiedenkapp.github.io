<!DOCTYPE html> <html> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Theory-Inspired Parameter Control Benchmarks for DAC | AndrÃ© Biedenkapp</title> <meta name="author" content="AndrÃ© Biedenkapp"/> <meta name="description" content="Accompanying blog post for our GECCO'22 paper"/> <meta name="keywords" content="Dynamic Algorithm Configuration, Reinforcement Learning, Learning to Learn"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ¤–</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://andrebiedenkapp.github.io/blog/2022/gecco/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <link rel="stylesheet" href="https://pyscript.net/releases/2022.09.1/pyscript.css"/> <script defer src="https://pyscript.net/releases/2022.09.1/pyscript.js"></script> <py-env> - numpy </py-env> <script src="/assets/js/distillpub/overrides.js"></script> </head> <d-front-matter> <script async type="text/json">{
      "title": "Theory-Inspired Parameter Control Benchmarks for DAC",
      "description": "Accompanying blog post for our GECCO'22 paper",
      "published": "May 22, 2022",
      "authors": [
        {
          "author": "AndrÃ© Biedenkapp",
          "authorURL": "",
          "affiliations": [
            {
              "name": "University of Freiburg",
              "url": ""
            }
          ]
        },
        {
          "author": "Nguyen Dang",
          "authorURL": "https://risweb.st-andrews.ac.uk/portal/en/persons/nguyen-thi-thanh-dang(5c6b63c1-b66c-420e-a55f-08b347ea3262).html",
          "affiliations": [
            {
              "name": "University of St. Andrews",
              "url": ""
            }
          ]
        },
        {
          "author": "Martin S. Krejca",
          "authorURL": "https://webia.lip6.fr/~krejca/index.html",
          "affiliations": [
            {
              "name": "Sorbonne UniversitÃ©, CNRS, LIP6",
              "url": ""
            }
          ]
        },
        {
          "author": "Frank Hutter",
          "authorURL": "https://ml.informatik.uni-freiburg.de/profile/hutter/",
          "affiliations": [
            {
              "name": "University of Freiburg, BCAI",
              "url": ""
            }
          ]
        },
        {
          "author": "Carola Doerr",
          "authorURL": "http://www-ia.lip6.fr/~doerr/index.html",
          "affiliations": [
            {
              "name": "Sorbonne UniversitÃ©, CNRS, LIP6",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script> </d-front-matter> <body class="fixed-top-navsticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">AndrÃ©Â </span>Biedenkapp</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link text-lowercase" href="/cv/">CV</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Theory-Inspired Parameter Control Benchmarks for DAC</h1> <p>Accompanying blog post for our GECCO'22 paper</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div><a href="#why-rls-on-leadingones">Why RLS on LeadingOnes?</a></div> <ul> <li><a href="#a-short-primer-on-leadingones-and-rls">A Short Primer on LeadingOnes and RLS</a></li> <li><a href="#ground-truth-and-optimal-policies">Ground Truth and Optimal Policies</a></li> </ul> <div><a href="#learning-dac-policies">Learning DAC Policies</a></div> <div><a href="#conclusion">Conclusion</a></div> <div><a href="#references">References</a></div> </nav> </d-contents> <p><strong>NOTE:</strong> We are using <a href="https://pyscript.net/" target="_blank" rel="noopener noreferrer"><font color="lightblue">pyscript</font></a> for the example below. Loading might take a bit longer.</p> <div id="pyexample" style="border: 2px solid #ccc !important; border-radius: 5px; padding: 5px 5px 5px 5px;"> <py-script src="/assets/python_scripts/2022-05-21-gecco/simple_plot.py"></py-script> <canvas id="envcanvas" height="20" style="background-color: black; alignment: center; width: 100%"> Loading... </canvas> <div class="output-group"> <span class="output-group-btn"> <div style="display: inline-block">LeadingOnes: </div> <div id="plot" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">Steps Taken: </div> <div id="timediv" style="display: inline-block">0</div> </span> </div> <div class="input-group"> <span class="input-group-btn"> <button type="button" class="btn btn-default" id="start-btn" style="alignment: left">START</button> <button type="button" class="btn btn-default" id="reset-btn" style="alignment: center">RESET</button> <button type="button" class="btn btn-default" id="stop-btn" style="alignment: right">STOP</button> <input type="range" min="1" max="100" value="1" step="1" class="slider" id="SpeedSlider" style=" -webkit-appearance: none; width: 21.5%; height: 10px; background: #d3d3d3; outline: none; opacity: 0.7; -webkit-transition: .2s; transition: opacity .2s; display: inline-block; margin-right: 10px; " oninput="this.nextElementSibling.value = this.value"> Speed: <output>1</output>% <input type="range" min="1" max="15" value="1" step="1" class="slider" id="LambdaSlider" style=" -webkit-appearance: none; width: 73%; height: 10px; background: #d3d3d3; outline: none; opacity: 0.7; -webkit-transition: .2s; transition: opacity .2s; display: inline-block; margin-right: 10px; " oninput="this.nextElementSibling.value = this.value"> Number of bitflips: <output>1</output> </span> </div> </div> <div class="figcaption"> <p> ${\color{gray}(1+1)}$RLS on a randomly initialized LeadingOnes problem. You can manually configure how many bits get flipped in each iteration via the lower slider. We only render the current best solution, thus some steps might not change the image. Cells that will not change anymore are colored in green. For pseudocode see <a href="#RLSpseudo">Algorithm 1</a>. </p> <br> </div> <p>To achieve peak-performance on a problem, it is often crucial to correctly setup, i.e. configure, the algorithm which is supposed to solve the problem. In many communities it has been observed that fixed parameter choices are often not optimal and that dynamic changes to parameter during the algorithms run can be highly beneficial (see, e.g., <d-cite key="SA83,HansenO01,battiti-book08,moulines-neurips11,BurkeGHKOOQ13,daniel-aaai16,loshchilov-iclr17a, jaderberg-arxiv17a,DoerrD18ga,parker-holder-neurips20"></d-cite>). The evolutionary algorithms community is no stranger to this observation. Under the heading of <em>parameter control</em> (for an overview see <d-cite key="Doerr2020"></d-cite>) various methods have been proposed to adapt parameters on the fly. More importantly however, the community has provided various theoretical insights.</p> <p>In a similar vain to parameter control, the novel <em>dynamic algorithm configuration (DAC)</em> <d-cite key="biedenkapp-ecai20"></d-cite> framework proposes to learn parameter adaptation policies in a dedicated offline learning phase. Once a policy was learned, it can then be used to adapt algorithm parameters on a variety of problem instances. Still, the field is very young and there is much to learn. In our recently accepted GECCO paper <em><a href="https://andrebiedenkapp.github.io/assets/pdf/22-gecco.pdf"><font color="lightblue">Theory-Inspired Parameter Control Benchmarks for Dynamic Algorithm Configuration</font></a></em> builds on such insights of the parameter control community to build benchmarks which can be used to evaluate DAC methods and policies.</p> <h2 id="why-rls-on-leadingones">Why RLS on LeadingOnes?</h2> <p>The short answer is, LeadingOnes is very well understood. The slightly longer answer is, LeadingOnes is one of the most rigorously studied problems in the parameter control community. The parameter control community has thoroughly studied the dynamic fitness-dependent selection of mutation rates for greedy evolutionary algorithms on LeadingOnes. Thus, it is very well understood how the expected runtime of such algorithms depend on the mutation rates during the run. Overall LeadingOnes is an important benchmark for parameter control studies both for empirical <d-cite key="DoerrDY16PPSN,DoerrW18"></d-cite> and theoretical analysis <d-cite key="LissovoiOW20,DoerrLOW18LO,DoerrDL21"></d-cite>. Thus, this makes LeadingOnes an ideal benchmark to also study DAC methods in depth. Further, the theoretical insights can be used to provide a ground truth on LeadingOnes. This was not possible for prior DAC benchmarks <d-cite key="eimer-ijcai21"></d-cite>, besides some manually designed artificial benchmarks.</p> <h3 id="a-short-primer-on-leadingones-and-rls">A Short Primer on LeadingOnes and RLS</h3> <p>If you are already familiar with the LeadingOnes problem you can skip this short introduction. LeadingOnes is perfectly named. For a bitstring of length $\color{gray}n$, the LeadingOnes problem is to maximize the number of uninterrupted leading ones in the bitsring.</p> <p>There are a variety of algorithms one could use for solving LeadingOnes. Here, we chose to use $\color{gray}(1+1)$RLS. The pseudo code for this is:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">RLS</span><span class="p">(</span><span class="n">problem_dimension</span><span class="p">,</span> <span class="n">max_budget</span><span class="p">):</span>
    <span class="n">partial_sol</span> <span class="o">=</span> <span class="n">numpy</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">problem_dimension</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">max_budget</span><span class="p">):</span>
        <span class="n">s</span> <span class="o">=</span> <span class="nf">get_current_state</span><span class="p">()</span>
        <span class="n">num_bits_to_flip</span> <span class="o">=</span> <span class="nf">policy</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">new_partial_sol</span> <span class="o">=</span> <span class="nf">flip</span><span class="p">(</span><span class="n">partial_sol</span><span class="p">,</span> <span class="n">num_bits_to_flip</span><span class="p">)</span>
        <span class="k">if</span> <span class="nf">fitness</span><span class="p">(</span><span class="n">new_partial_sol</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="nf">fitness</span><span class="p">(</span><span class="n">partial_sol</span><span class="p">):</span>
            <span class="n">partial_sol</span> <span class="o">=</span> <span class="n">new_partial_sol</span></code></pre></figure> <div class="figcaption"> <p>Algorithm 1: Pseudocode for ${\color{gray}(1+1)}$RLS </p> </div> <p>The algorithm starts from a randomly initialized bitstring and in each iteration randomly flips <d-code language="python">num_bits_to_flip</d-code>. The so created new solution candidate is compared to the old one. The old one is replaced by the new one if the latter one is not worse than the former one. When using an algorithm for solving the LeadingOnes problem, we are interested in setting the algorithm up such that we solve the problem using as few function evaluations as possible, or in other words in as few iterations as possible. At the top of this post you can find a working implementation of this setup where you are in charge of setting the number of bits to flip in each iteration. If youâ€™ve played around with this setting a bit, you might have noticed a few things:</p> <ul> <li>A too high number of bits to flip becomes detrimental the more leading ones we have.</li> <li>Always only flipping one bit is a valid strategy but might take a long time (depending on the initialization).</li> <li>Decreasing the number of bits to flip over time fairly reliably reduces the required running time.</li> </ul> <h3 id="ground-truth-and-optimal-policies">Ground Truth and Optimal Policies</h3> <p>It was proven <d-cite key="doerr-tcs19a"></d-cite> that we can compute the probability of improving the current partial solution of length $\color{gray}n$ with fitness value $\color{gray}i\leq n$ by flipping $\color{gray}r$ bits as \(\color{gray} q(r,i)=\frac{r}{n}\cdot\prod_{j\in\left[1,\ldots,r-1\right]}\frac{n-i-j}{n-j}\). Further, an optimal policy that can choose to flip any number of bits in $\color{gray}\left[1,\ldots,n\right]$ satisfies $\color{gray}\pi_{\text{opt}}\colon i\mapsto\lfloor n/(i+1)\rfloor$. Thus, if our current solution has fitness $\color{gray}0$ (i.e., no leading ones) we should flip all bits. If we only have one leading one, we should flip exactly $\color{gray}\lfloor n/2\rfloor$ bits, and so on. Letâ€™s compare this optimal policy to static ones:</p> <div id="pyexample-comparison" style="border: 2px solid #ccc !important; border-radius: 5px; padding: 5px 5px 5px 5px;"> <py-script src="/assets/python_scripts/2022-05-21-gecco/comparison_leading_ones_full.py"></py-script> <div style="font-style: oblique; font-weight: bold; display: inline-block">Optimal Policy:</div> <div style="display: inline-block">$\color{gray}\pi_{\text{opt}}($<div style="display: inline-block" id="opt-f-val">?</div>$\color{gray})\mapsto$ </div> <div id="r-comparison-optimal" style="display: inline-block">?</div> <canvas id="comparison-canvas-optimal" height="20" style="background-color: black; alignment: center; width: 100%"> Loading... </canvas> <div class="output-group-comparison-static"> <span class="output-group-btn-comparison-static"> <div style="display: inline-block">LeadingOnes: </div> <div id="plot-comparison-optimal" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">Steps Taken: </div> <div id="timdiv-comparison-optimal" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">#Solved: </div> <div id="solved-comparison-optimal" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">$\color{gray}\mu_{\text{steps}}$: </div> <div id="avg-comparison-optimal" style="display: inline-block; margin-right: 10px">0</div> </span> </div> <div style="font-style: oblique; font-weight: bold">Static Policy:</div> <canvas id="comparison-canvas-static" height="20" style="background-color: black; alignment: center; width: 100%"> Loading... </canvas> <div class="output-group-comparison-static"> <span class="output-group-btn-comparison-static"> <div style="display: inline-block">LeadingOnes: </div> <div id="plot-comparison-static" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">Steps Taken: </div> <div id="timediv-comparison-static" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">#Solved: </div> <div id="solved-comparison-static" style="display: inline-block; margin-right: 10px">0</div> <div style="display: inline-block">$\color{gray}\mu_{\text{steps}}$: </div> <div id="avg-comparison-static" style="display: inline-block">0</div> </span> </div> <div class="input-group-comparison-static"> <span class="input-group-btn"> <button type="button" class="btn btn-default" id="start-btn-comparison-static" style="alignment: left">START</button> <button type="button" class="btn btn-default" id="reset-btn-comparison-static" style="alignment: center">RESET</button> <button type="button" class="btn btn-default" id="stop-btn-comparison-static" style="alignment: right">STOP</button> <input type="range" min="1" max="100" value="1" step="1" class="slider" id="SpeedSlider-comparison-static" style=" -webkit-appearance: none; width: 21.5%; height: 10px; background: #d3d3d3; outline: none; opacity: 0.7; -webkit-transition: .2s; transition: opacity .2s; display: inline-block; margin-right: 10px; " oninput="this.nextElementSibling.value = this.value"> Speed: <output>1</output>% <input type="range" min="1" max="15" value="1" step="1" class="slider" id="LambdaSlider-comparison-static" style=" -webkit-appearance: none; width: 73%; height: 10px; background: #d3d3d3; outline: none; opacity: 0.7; -webkit-transition: .2s; transition: opacity .2s; display: inline-block; margin-right: 10px; " oninput="this.nextElementSibling.value = this.value"> Number of bitflips: <output>1</output> </span> </div> </div> <div class="figcaption"> <p> </p> </div> <p>We can see that the optimal policy is quite a bit faster at solving the LeadingOnes example. However, what about policies that are restricted and cannot choose from all values in $\color{gray}\left[1,\ldots,n\right]$? In our paper, we present a method to compute the optimal policy for any such restricted choice. In essence, we can use the probability of improvement as defined above and only need to compare the probability of consecutive elements<d-footnote>We assume the portfolio is always sorted.</d-footnote> of the portfolio. Whenever we have a higher probability of improvement with the smaller portfolio element, we switch to that. So, for any $\color{gray}n$ and portfolio $\color{gray}\mathcal{K}$ we can compute the optimal policy and thus generate ground-truth about the behaviour of $\color{gray}(1+1)$RLS.<d-footnote>Note that 1 always needs to be included as we otherwise can't guarantee that a solution will be found.</d-footnote> This ability to compute the optimal policy for any portfolio (i.e., <em>configuration space</em>) makes this setting ideal to study how different problem sizes and configuration spaces influence DAC methods.</p> <h2 id="learning-dac-policies">Learning DAC Policies</h2> <p>Now that we know all about the benchmark, lets use it to gain insights into a DAC method<d-footnote>If you need a lightweight introduction to DAC we refer to <d-cite key="biedenkapp-automl20"></d-cite></d-footnote>. To give an example of the use-case of this benchmark we train a small DDQN agent to dynamically configure the number of bit flips of RLS on LeadingOnes based on the observed fitness value.</p> <p><img src="/assets/img/blog/2022-05-21-gecco/n50_policy.png" class="img-fluid rounded z-depth-1" data-zoomable="true" style="background-color: white; width: 49%; display: inline-block"> <img src="/assets/img/blog/2022-05-21-gecco/n50_policies_k5.png" class="img-fluid rounded z-depth-1" data-zoomable="true" style="background-color: white; width: 49%; display: inline-block"></p> <div class="figcaption"> <p> Comparison of a learned policy (dqn) compared to optimal ones. The dotted green line used the same restricted configuration space as the DQN. (left): The configuration space consists of three evenly spread values [1, 16, 32]. (right): The configuration space consists of five values [1, 2, 4, 8 16]. </p> </div> <p>Our first results (shown in the figures above) show that the DQN is indeed capable of learning optimal policies. Indeed on the same restricted configuration space for bitstrings of length 50, the DQN quickly learns the to play the optimal policy or ones that result in virtually the same reward.</p> <p>The availability of ground truth however not only enables us to compare the learned performance to the known optimal one, we can also study the limits of the chosen DAC method. For example, we can evaluate how the same DQNs learning capabilities scale with the size of the configuration space.</p> <p><img src="/assets/img/blog/2022-05-21-gecco/eval-n100_evenly_spread_boxplot.png" class="img-fluid rounded z-depth-1" data-zoomable="true" style="background-color: white"></p> <div class="figcaption"> <p> Comparison of a learned policy (dqn) compared to optimal and random ones on problems of size 100 with varying portfolio sizes. For $\color{gray}k\geq7$ we plot three distinct runs to highlight the increased instability of DQN. For $\color{gray}k = 15$ none of the dqn runs were capable of learning meaningful policies. </p> </div> <p>Overall we could observe that the chosen DAC method, with its used parameter settings was capable of learning optimal policies but struggled to scale to larger action spaces as well as portfolio sizes. For more details we refer the interested reader to our paper.</p> <h2 id="conclusion">Conclusion</h2> <p>Our work presents a novel benchmark that is useful for both parameter control and DAC research. The benchmark fills an important gap in the existing benchmarks for DAC research as it enables us to compute optimal policies. We thus can easily evaluate the quality of learned DAC policies and as well as DAC techniques themselves. We showed how we can use the benchmark to gain insights into a DAC method and explored settings in which the chosen DQN method started to break down. We hope that our work is the first of many exchanges of benchmarks between the parameter control and dynamic algorithm configuration communities. With the growing literature on parameter control and its theoretical analysis we hope to provide other use-cases with a known ground truth.</p> <p>Our code and data are publicly available at <span style="color:blue"><a href="https://github.com/ndangtt/LeadingOnesDAC" target="_blank" rel="noopener noreferrer"><font color="lightblue">https://github.com/ndangtt/LeadingOnesDAC</font></a></span> and the benchmark has recently been merged into DACBench. For feedback or questions, feel free to reach out to us.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> </div> <footer class="sticky-bottom mt-5"> <div class="container"> Â© Copyright 2026 AndrÃ© Biedenkapp. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> &amp; <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a>. Last updated: Feb 09, 2026. <a href="https://andrebiedenkapp.github.io/impressum/">Impressum</a>. <a href="https://andrebiedenkapp.github.io/privacy-policy/">Privacy Policy</a>. </div> </footer> <d-bibliography src="/assets/bibliography/2022-05-21-gecco.bib"></d-bibliography> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> </body> </html>